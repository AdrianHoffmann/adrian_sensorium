{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo containing all the steps from loading data to submission using the `hub` package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### This notebook will show how to\n",
    "- load the checkpoints of our baseline models\n",
    "- use our API to generate a submission .csv file\n",
    "- use the .csv file to make a submission\n",
    "\n",
    "We also show how\n",
    "- we extract the ground truth responses from a dataset\n",
    "- we use these ground truth responses and the submitted files to calculate the score of the live leaderboard of our competition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/hub/util/check_latest_version.py:32: UserWarning: A newer version of hub (2.3.4) is available. It's recommended that you update to the latest version using `pip install -U hub`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# the package that we host our data on for cloud based access without the need to download our data at all\n",
    "import hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 1. Load the train and test datasets and create the corresponding dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening dataset in read-only mode as you don't have write permissions.\n",
      "hub://mohammadbashiri/npc-mouse1-train loaded successfully.\n",
      "This dataset can be visualized at https://app.activeloop.ai/mohammadbashiri/npc-mouse1-train.\n",
      "Opening dataset in read-only mode as you don't have write permissions.\n",
      "hub://mohammadbashiri/npc-mouse1-train loaded successfully.\n",
      "This dataset can be visualized at https://app.activeloop.ai/mohammadbashiri/npc-mouse1-train.\n",
      "Opening dataset in read-only mode as you don't have write permissions.\n",
      "hub://mohammadbashiri/npc-mouse1-test loaded successfully.\n",
      "This dataset can be visualized at https://app.activeloop.ai/mohammadbashiri/npc-mouse1-test.\n"
     ]
    }
   ],
   "source": [
    "dataset_id = 'mouse1'\n",
    "\n",
    "# get the data from Activeloop\n",
    "train_dataset_train = hub.load(f\"hub://mohammadbashiri/npc-{dataset_id}-train\")\n",
    "train_dataset_val = hub.load(f\"hub://mohammadbashiri/npc-{dataset_id}-train\")\n",
    "test_dataset = hub.load(f\"hub://mohammadbashiri/npc-{dataset_id}-test\")\n",
    "\n",
    "# split the trainset into train and validation (i.e. modify the index of the corresponding dataset)\n",
    "n_training_samples = len(train_dataset_train)\n",
    "train_indices, val_indices = train_test_split(np.arange(n_training_samples), train_size=0.7)\n",
    "train_samples_mask = np.isin(np.arange(n_training_samples), train_indices)\n",
    "train_dataset_train.index.values[0].value = tuple(np.where(train_samples_mask)[0].tolist())\n",
    "train_dataset_val.index.values[0].value = tuple(np.where(~train_samples_mask)[0].tolist())\n",
    "\n",
    "# create the dataloaders\n",
    "train_dataloader = train_dataset_train.pytorch(batch_size=16, shuffle=True, transform={'inputs': transforms.ToTensor(), 'targets': None, 'image_ids': None, 'trial_indices': None})\n",
    "val_dataloader = train_dataset_val.pytorch(batch_size=16, shuffle=False, transform={'inputs': transforms.ToTensor(), 'targets': None, 'image_ids': None, 'trial_indices': None})\n",
    "test_dataloader = test_dataset.pytorch(batch_size=16, shuffle=False, transform={'inputs': transforms.ToTensor(), 'image_ids': None, 'trial_indices': None})\n",
    "\n",
    "# Combine the dataloaders into a single object (dict)\n",
    "dataloaders = {\"train\": {dataset_id: train_dataloader},\n",
    "               \"validation\": {dataset_id: val_dataloader},\n",
    "               \"test\": {dataset_id: test_dataloader}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': {'mouse1': <torch.utils.data.dataloader.DataLoader at 0x7fbd0568eee0>},\n",
       " 'validation': {'mouse1': <torch.utils.data.dataloader.DataLoader at 0x7fbd05f67130>},\n",
       " 'test': {'mouse1': <torch.utils.data.dataloader.DataLoader at 0x7fbd057d2670>}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataloaders have the same behavior as in demo notebooks 1-3\n",
    "dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Initialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/src/neuralpredictors/neuralpredictors/layers/readouts/base.py:72: UserWarning: Use of 'gamma_readout' is deprecated. Please consider using the readout's feature-regularization parameter instead\n",
      "  warnings.warn(\n",
      "/src/neuralpredictors/neuralpredictors/layers/readouts/base.py:88: UserWarning: Readout is NOT initialized with mean activity but with 0!\n",
      "  warnings.warn(\"Readout is NOT initialized with mean activity but with 0!\")\n"
     ]
    }
   ],
   "source": [
    "from sensorium.models import stacked_core_full_gauss_readout\n",
    "\n",
    "model_config = {'pad_input': False,\n",
    "              'stack': -1,\n",
    "              'layers': 4,\n",
    "              'input_kern': 9,\n",
    "              'gamma_input': 6.3831,\n",
    "              'gamma_readout': 0.0076,\n",
    "              'hidden_dilation': 1,\n",
    "              'hidden_kern': 7,\n",
    "              'hidden_channels': 64,\n",
    "              'depth_separable': True,\n",
    "              'init_sigma': 0.1,\n",
    "              'init_mu_range': 0.3,\n",
    "              'gauss_type': 'full',\n",
    "               }\n",
    "\n",
    "model = stacked_core_full_gauss_readout(dataloaders, seed=1, **model_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 9/9 [00:04<00:00,  2.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[001|00/05] ---> 0.005140737484911137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 9/9 [00:04<00:00,  2.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[002|01/05] -/-> -0.0016359479945072125\n",
      "Restoring best model! -0.001636 ---> 0.005141\n"
     ]
    }
   ],
   "source": [
    "from sensorium.training import standard_trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# using a trainer with only 2 iterations for simplicity\n",
    "\n",
    "trainer_config = {'max_iter': 2,\n",
    "                  'verbose': False,\n",
    "                  'lr_decay_steps': 4,\n",
    "                  'avg_loss': False,\n",
    "                  'lr_init': 0.009}\n",
    "\n",
    "score, output, state_dict = standard_trainer(model, dataloaders, seed=1, **trainer_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 4. Prepare the submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trial_indices</th>\n",
       "      <th>image_ids</th>\n",
       "      <th>prediction</th>\n",
       "      <th>neuron_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.8660333156585693, 0.7536219954490662, 0.667...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[1.1662379503250122, 0.9683790802955627, 1.193...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.9244330525398254, 0.9667186141014099, 0.837...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>[1.0985108613967896, 0.9715718626976013, 1.172...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>[1.0623140335083008, 0.9847257137298584, 1.053...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>95</td>\n",
       "      <td>9</td>\n",
       "      <td>[0.9583678245544434, 0.788209080696106, 0.8644...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>96</td>\n",
       "      <td>9</td>\n",
       "      <td>[1.042254090309143, 1.2295119762420654, 0.9393...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>97</td>\n",
       "      <td>9</td>\n",
       "      <td>[1.0805977582931519, 1.0807799100875854, 1.050...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>98</td>\n",
       "      <td>9</td>\n",
       "      <td>[0.9569833874702454, 1.0637223720550537, 0.947...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99</td>\n",
       "      <td>9</td>\n",
       "      <td>[1.2293667793273926, 1.042912483215332, 0.9154...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    trial_indices  image_ids  \\\n",
       "0               0          0   \n",
       "1               1          0   \n",
       "2               2          0   \n",
       "3               3          0   \n",
       "4               4          0   \n",
       "..            ...        ...   \n",
       "95             95          9   \n",
       "96             96          9   \n",
       "97             97          9   \n",
       "98             98          9   \n",
       "99             99          9   \n",
       "\n",
       "                                           prediction  \\\n",
       "0   [0.8660333156585693, 0.7536219954490662, 0.667...   \n",
       "1   [1.1662379503250122, 0.9683790802955627, 1.193...   \n",
       "2   [0.9244330525398254, 0.9667186141014099, 0.837...   \n",
       "3   [1.0985108613967896, 0.9715718626976013, 1.172...   \n",
       "4   [1.0623140335083008, 0.9847257137298584, 1.053...   \n",
       "..                                                ...   \n",
       "95  [0.9583678245544434, 0.788209080696106, 0.8644...   \n",
       "96  [1.042254090309143, 1.2295119762420654, 0.9393...   \n",
       "97  [1.0805977582931519, 1.0807799100875854, 1.050...   \n",
       "98  [0.9569833874702454, 1.0637223720550537, 0.947...   \n",
       "99  [1.2293667793273926, 1.042912483215332, 0.9154...   \n",
       "\n",
       "                                           neuron_ids  \n",
       "0   [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...  \n",
       "1   [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...  \n",
       "2   [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...  \n",
       "3   [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...  \n",
       "4   [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...  \n",
       "..                                                ...  \n",
       "95  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...  \n",
       "96  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...  \n",
       "97  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...  \n",
       "98  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...  \n",
       "99  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sensorium.utility.submission import generate_submission_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "generate_submission_file(trained_model=model,\n",
    "                                    test_dataloader=dataloaders[\"test\"][dataset_id],\n",
    "                                    path='./submission_files/hub_demo_submission_file.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.read_csv('./submission_files/hub_demo_submission_file.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
